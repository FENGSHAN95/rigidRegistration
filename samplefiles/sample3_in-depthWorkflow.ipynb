{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In depth workflow\n",
    "The code below provides a sample workflow for registering data which is particularly challenging, and may require some of the more detailed features of the rigidregistration package for successful processing.\n",
    "\n",
    "These first few cells are prepretory: importing the necessary python libraries and functions, loading and pre-inspecting the data, and instantiating the rigidregistration 'imstack' object.  The bulk of the relevant functions here are defined as methods of the imstack object.  \n",
    "\n",
    "In this example, data which is formatted as .tif files are loaded using the tifffile package.  For other file formats common to electron microscopy data (including, e.g., .dm3, .ser...) we recommend the hyperspy package for i/o handling.  See hyperspy.org.\n",
    "\n",
    "If you find this code useful in your own research, please cite the associated publication:\n",
    "\"Image registration of low signal-to-noise cryo-STEM data\", Ultramicroscopy (2018), DOI: 10.1016/j.ultramic.2018.04.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# Import global libraries and functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import splitext, basename\n",
    "from time import time\n",
    "from tifffile import imread, imsave\n",
    "\n",
    "# Import local libraries\n",
    "import rigidregistration\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sample_data/CdSe_NPs.tif.\n"
     ]
    }
   ],
   "source": [
    "# Load data.  \n",
    "# Final axis of stack variable should iterate over images.\n",
    "# For best performance, data should be normalized between 0 and 1\n",
    "\n",
    "f=\"sample_data/CdSe_NPs.tif\"           # Filepath to data\n",
    "stack=np.rollaxis(imread(f),0,3)       # Rearrange axes so final axis iterates over images\n",
    "stack=stack[:,:,:]/float(2**16)        # Normalize data between 0 and 1\n",
    "print(\"Analyzing {}.\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data in preparation for registration\n",
    "\n",
    "for i in range(5,10):                      # Select which images from the stack to display\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2)\n",
    "    ax1.matshow(stack[:,:,i],cmap='gray')\n",
    "    ax2.matshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(stack[:,:,i])))),cmap='gray',vmin=np.average(np.log(np.abs(np.fft.fft2(stack[:,:,i]))))) \n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate imstack object, and get all FFTs\n",
    "\n",
    "s=rigidregistration.stackregistration.imstack(stack)    # Instantiage imstack object.\n",
    "s.getFFTs()                                             # Calculate the FFTs of each image in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fourier masking\n",
    "Select a Fourier mask, defining which information will be weighted more or less to calculate the image shifts. \n",
    "There are two choices to be made: the cutoff frequency, and mask shape.  It is also possible to define a unique Fourier mask.\n",
    "\n",
    "**1. The cutoff frequency**\n",
    "\n",
    "In all cases, the parameter n controls the mask cutoff frequency; features smaller than ~n pixels will be ignored during image correlation.\n",
    "For data with higher SNR, choosing a mask with n at the information limit is frequently sufficient.\n",
    "For low-SNR data, choosing a mask with a cutoff frequency near the primary Bragg peaks is often preferable, as this heavily weights low frequency information to avoid unit-cell hops, but ideally contains just enough lattice information to 'lock-in' to the lattice.\n",
    "\n",
    "**2. The mask shape**\n",
    "\n",
    "Supported apodization functions for makeFourierMask() method are \"bandpass\", \"lowpass\", \"hann\", \"hamming\", \"blackman\", \"gaussian\", \"none\".\n",
    "For lattices lacking high rotational symmetry, an anisotropic mask is generally preferable to avoid overweighting one lattice direction, discussed further below.\n",
    "Details functional forms can be found in the source code.\n",
    "\n",
    "**3. Defining a unique mask**\n",
    "\n",
    "The imstack object contains several meshgrids which correspond to Fourier space coordinates, facilitating defining a unique Fourier mask.  See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore mask shape options\n",
    "\n",
    "# The displayed plots are:\n",
    "# Left: The full FFT in black and white, with a colored, semitransparent overlay showing the mask\n",
    "# Middle: The FFT multiplied by the weighting mask\n",
    "# Right: The cross correlation of a selected pair of images, weighted by the chosen mask\n",
    "\n",
    "\n",
    "masktypes=[\"bandpass\",\"lowpass\",\"hann\",\"hamming\",\"blackman\",\"gaussian\",\"none\"]   # List of mask shapes\n",
    "n=4                                                                              # Set cutoff frequency\n",
    "\n",
    "i,j = 5,9                                    # Choose image pair to cross correlate\n",
    "for masktype in masktypes:                   # Iterate over mask types\n",
    "    s.makeFourierMask(mask=masktype,n=n)     # Set the selected Fourier mask\n",
    "    s.show_Fourier_mask(i=i,j=j)             # Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary n, the cutoff frequency\n",
    "\n",
    "# In a typical workflow, this parameter is varied and the effect on the cross correlation is optimized\n",
    "\n",
    "masktype=\"hann\"\n",
    "\n",
    "i,j = 5,9                                    # Choose image pair\n",
    "for n in np.arange(2,12,2):                  # Select n values to test\n",
    "    s.makeFourierMask(mask=masktype,n=n)     # Set the selected Fourier mask\n",
    "    s.show_Fourier_mask(i=i,j=j)             # Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elliptical Gaussian masks\n",
    "\n",
    "# The makeFourierMask_eg() method creates an elliptical gaussian mask, with parameters n1, n2, and theta.\n",
    "# n1, n2 define the cutoff frequencies along the two primary axes \n",
    "# theta defines the mask tilt, in degrees.\n",
    "\n",
    "n1=4\n",
    "n2=2\n",
    "theta=20\n",
    "\n",
    "s.makeFourierMask_eg(n1=n1,n2=n2,theta=np.radians(theta))   # Set the selected mask\n",
    "s.show_Fourier_mask(i=i,j=j)                                # Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary elliptical Gaussian angle\n",
    "\n",
    "# The three parameters (n1,n2,theta) can be varied and optimized.\n",
    "\n",
    "n1=4\n",
    "n2=2\n",
    "thetas=[90,75,60,45,30,15,0]\n",
    "\n",
    "i,j = 5,9\n",
    "for theta in thetas:\n",
    "    s.makeFourierMask_eg(n1=n1,n2=n2,theta=np.radians(theta))\n",
    "    s.show_Fourier_mask(i=i,j=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique mask\n",
    "\n",
    "# There are three attributes of the imstack object which define Fourier space coordinates, and can be used to define \n",
    "# a Fourier mask.  kx and ky define rectangular Fourier coordinates, and kr defines polar Fourier coordinates.\n",
    "# See the examples below.\n",
    "\n",
    "circular_mask = np.abs(s.kr)<50                      # Make a circular mask\n",
    "s.makeUserDefinedFourierMask(circular_mask)          # Set mask\n",
    "s.show_Fourier_mask()\n",
    "\n",
    "square_mask = (np.abs(s.kx)<50)*(np.abs(s.ky)<50)    # Make a square mask\n",
    "s.makeUserDefinedFourierMask(square_mask)            # Set mask\n",
    "s.show_Fourier_mask(i=i,j=j)\n",
    "\n",
    "kmax=s.nx/4                                          # Set cutoff frequency\n",
    "barlett_mask = (s.kr<kmax)*(1 - s.kr/kmax)           # Make bartlett mask\n",
    "s.makeUserDefinedFourierMask(barlett_mask)           # Set mask\n",
    "s.show_Fourier_mask(i=i,j=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate image shifts\n",
    "Calculate the relative shifts between all pairs of images from their cross correlations.\n",
    "\n",
    "Analytically, for two functions which are identical except for some shift, the shift is given by the maximum value of their cross correlation.\n",
    "Here, the maximum of the cross correlation may be found in one of two ways: finding the brightest pixel, or fitting gaussian functions.  Which method is used is controlled by the findMaxima parameter.\n",
    "\n",
    "** 1. Brightest pixel **\n",
    "\n",
    "The shift is given directly by the position of the brightest pixel in the cross correlation.  The relative shifts are thus determined with resolution of 1 pixel - however, the final shifts which are applied to the images before averaging will be determined using all of the relative image shifts between all pairs of images, thus the final shifts may still be determined with subpixel resolution, with an accuracy that generally improves with the number of images in the stack.  This is the fastest approach.  This method is selected by setting findMaxima=\"pixel\".\n",
    "\n",
    "** 2. Gaussian fitting **\n",
    "\n",
    "Fitting a continuous function to the maximum of the cross correlation is a simple way to find the shift between an image pair with subpixel resolution.  For images of atomic lattices, a Gaussian is a natural choice for a fitting function.\n",
    "\n",
    "Separately, for images of crystal lattices, 'unit cell hop' errors can occur, wherein the calculated shift between a pair of images is incorrect by a multiple of the primitive lattice vectors.  When the real space sampling of the image is low enough that each atomic column is only a handful of pixels across, unit cell hops become increasingly common due to sampling error.  This can be largely handled by performing Gaussian fits to the regions near the brighest few pixels, and then finding the cross correlation maximum from these continuous fits.\n",
    "\n",
    "This method is selected by setting findMaxima=\"gf\".  Before running the Gaussian fitting method, three additional parameters for the fitting should be set by calling s.setGaussianFitParams().  These are:\n",
    "\n",
    "  * sigma_guess: sets the initial guess for the standard deviation of the guassian fits, in pixels.  This may be estimated simply and quickly by observing the peak widths in the cross correlations or the width of atomic columns in the raw data.\n",
    "\n",
    "  * window_radius: sets the size of the region about the brightest pixel which is used to fit a gaussian.  Should be set such that neighboring cross correlation peaks are excluded.  The window used is a square region of size length 2xwindow_radius+1.\n",
    "\n",
    "  * num_peaks: sets how many of the brightest pixels to fit gaussians to. Typically 3-5 are sufficient to handle sampling problems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make elliptical Gaussian mask.\n",
    "# The type and parameters of the Fourier mask are determined by varying parameters in the previous section.\n",
    "\n",
    "n1=12\n",
    "n2=9.106\n",
    "theta=1.42\n",
    "\n",
    "s.makeFourierMask_eg(n1=n1,n2=n2,theta=theta)\n",
    "s.show_Fourier_mask(i=i,j=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlating images 0 and 1\n",
      "Correlating images 0 and 2\n",
      "Correlating images 0 and 3\n",
      "Correlating images 0 and 4\n",
      "Correlating images 0 and 5\n",
      "Correlating images 0 and 6\n",
      "Correlating images 0 and 7\n",
      "Correlating images 0 and 8\n",
      "Correlating images 0 and 9\n",
      "Correlating images 0 and 10\n",
      "Correlating images 0 and 11\n",
      "Correlating images 0 and 12\n",
      "Correlating images 0 and 13\n",
      "Correlating images 0 and 14\n",
      "Correlating images 0 and 15\n",
      "Correlating images 0 and 16\n",
      "Correlating images 0 and 17\n",
      "Correlating images 0 and 18\n",
      "Correlating images 0 and 19\n",
      "Correlating images 0 and 20\n",
      "Correlating images 0 and 21\n",
      "Correlating images 0 and 22\n",
      "Correlating images 0 and 23\n",
      "Correlating images 0 and 24\n",
      "Correlating images 0 and 25\n",
      "Correlating images 0 and 26\n",
      "Correlating images 1 and 2\n",
      "Correlating images 1 and 3\n",
      "Correlating images 1 and 4\n",
      "Correlating images 1 and 5\n",
      "Correlating images 1 and 6\n",
      "Correlating images 1 and 7\n",
      "Correlating images 1 and 8\n",
      "Correlating images 1 and 9\n",
      "Correlating images 1 and 10\n",
      "Correlating images 1 and 11\n",
      "Correlating images 1 and 12\n",
      "Correlating images 1 and 13\n",
      "Correlating images 1 and 14\n",
      "Correlating images 1 and 15\n",
      "Correlating images 1 and 16\n",
      "Correlating images 1 and 17\n",
      "Correlating images 1 and 18\n",
      "Correlating images 1 and 19\n",
      "Correlating images 1 and 20\n",
      "Correlating images 1 and 21\n",
      "Correlating images 1 and 22\n",
      "Correlating images 1 and 23\n",
      "Correlating images 1 and 24\n",
      "Correlating images 1 and 25\n",
      "Correlating images 1 and 26\n",
      "Correlating images 2 and 3\n",
      "Correlating images 2 and 4\n",
      "Correlating images 2 and 5\n",
      "Correlating images 2 and 6\n",
      "Correlating images 2 and 7\n",
      "Correlating images 2 and 8\n",
      "Correlating images 2 and 9\n",
      "Correlating images 2 and 10\n",
      "Correlating images 2 and 11\n",
      "Correlating images 2 and 12\n",
      "Correlating images 2 and 13\n",
      "Correlating images 2 and 14\n",
      "Correlating images 2 and 15\n",
      "Correlating images 2 and 16\n",
      "Correlating images 2 and 17\n",
      "Correlating images 2 and 18\n",
      "Correlating images 2 and 19\n",
      "Correlating images 2 and 20\n",
      "Correlating images 2 and 21\n",
      "Correlating images 2 and 22\n",
      "Correlating images 2 and 23\n",
      "Correlating images 2 and 24\n",
      "Correlating images 2 and 25\n",
      "Correlating images 2 and 26\n",
      "Correlating images 3 and 4\n",
      "Correlating images 3 and 5\n",
      "Correlating images 3 and 6\n",
      "Correlating images 3 and 7\n",
      "Correlating images 3 and 8\n",
      "Correlating images 3 and 9\n",
      "Correlating images 3 and 10\n",
      "Correlating images 3 and 11\n",
      "Correlating images 3 and 12\n",
      "Correlating images 3 and 13\n",
      "Correlating images 3 and 14\n",
      "Correlating images 3 and 15\n",
      "Correlating images 3 and 16\n",
      "Correlating images 3 and 17\n",
      "Correlating images 3 and 18\n",
      "Correlating images 3 and 19\n",
      "Correlating images 3 and 20\n",
      "Correlating images 3 and 21\n",
      "Correlating images 3 and 22\n",
      "Correlating images 3 and 23\n",
      "Correlating images 3 and 24\n",
      "Correlating images 3 and 25\n",
      "Correlating images 3 and 26\n",
      "Correlating images 4 and 5\n",
      "Correlating images 4 and 6\n",
      "Correlating images 4 and 7\n",
      "Correlating images 4 and 8\n",
      "Correlating images 4 and 9\n",
      "Correlating images 4 and 10\n",
      "Correlating images 4 and 11\n",
      "Correlating images 4 and 12\n",
      "Correlating images 4 and 13\n",
      "Correlating images 4 and 14\n",
      "Correlating images 4 and 15\n",
      "Correlating images 4 and 16\n",
      "Correlating images 4 and 17\n",
      "Correlating images 4 and 18\n",
      "Correlating images 4 and 19\n",
      "Correlating images 4 and 20\n",
      "Correlating images 4 and 21\n",
      "Correlating images 4 and 22\n",
      "Correlating images 4 and 23\n",
      "Correlating images 4 and 24\n",
      "Correlating images 4 and 25\n",
      "Correlating images 4 and 26\n",
      "Correlating images 5 and 6\n",
      "Correlating images 5 and 7\n",
      "Correlating images 5 and 8\n",
      "Correlating images 5 and 9\n",
      "Correlating images 5 and 10\n",
      "Correlating images 5 and 11\n",
      "Correlating images 5 and 12\n",
      "Correlating images 5 and 13\n",
      "Correlating images 5 and 14\n",
      "Correlating images 5 and 15\n",
      "Correlating images 5 and 16\n",
      "Correlating images 5 and 17\n",
      "Correlating images 5 and 18\n",
      "Correlating images 5 and 19\n",
      "Correlating images 5 and 20\n",
      "Correlating images 5 and 21\n",
      "Correlating images 5 and 22\n",
      "Correlating images 5 and 23\n",
      "Correlating images 5 and 24\n",
      "Correlating images 5 and 25\n",
      "Correlating images 5 and 26\n",
      "Correlating images 6 and 7\n",
      "Correlating images 6 and 8\n",
      "Correlating images 6 and 9\n",
      "Correlating images 6 and 10\n",
      "Correlating images 6 and 11\n",
      "Correlating images 6 and 12\n",
      "Correlating images 6 and 13\n",
      "Correlating images 6 and 14\n",
      "Correlating images 6 and 15\n",
      "Correlating images 6 and 16\n",
      "Correlating images 6 and 17\n",
      "Correlating images 6 and 18\n",
      "Correlating images 6 and 19\n",
      "Correlating images 6 and 20\n",
      "Correlating images 6 and 21\n",
      "Correlating images 6 and 22\n",
      "Correlating images 6 and 23\n",
      "Correlating images 6 and 24\n",
      "Correlating images 6 and 25\n",
      "Correlating images 6 and 26\n",
      "Correlating images 7 and 8\n",
      "Correlating images 7 and 9\n",
      "Correlating images 7 and 10\n",
      "Correlating images 7 and 11\n",
      "Correlating images 7 and 12\n",
      "Correlating images 7 and 13\n",
      "Correlating images 7 and 14\n",
      "Correlating images 7 and 15\n",
      "Correlating images 7 and 16\n",
      "Correlating images 7 and 17\n",
      "Correlating images 7 and 18\n",
      "Correlating images 7 and 19\n",
      "Correlating images 7 and 20\n",
      "Correlating images 7 and 21\n",
      "Correlating images 7 and 22\n",
      "Correlating images 7 and 23\n",
      "Correlating images 7 and 24\n",
      "Correlating images 7 and 25\n",
      "Correlating images 7 and 26\n",
      "Correlating images 8 and 9\n",
      "Correlating images 8 and 10\n",
      "Correlating images 8 and 11\n",
      "Correlating images 8 and 12\n",
      "Correlating images 8 and 13\n",
      "Correlating images 8 and 14\n",
      "Correlating images 8 and 15\n",
      "Correlating images 8 and 16\n",
      "Correlating images 8 and 17\n",
      "Correlating images 8 and 18\n",
      "Correlating images 8 and 19\n",
      "Correlating images 8 and 20\n",
      "Correlating images 8 and 21\n",
      "Correlating images 8 and 22\n",
      "Correlating images 8 and 23\n",
      "Correlating images 8 and 24\n",
      "Correlating images 8 and 25\n",
      "Correlating images 8 and 26\n",
      "Correlating images 9 and 10\n",
      "Correlating images 9 and 11\n",
      "Correlating images 9 and 12\n",
      "Correlating images 9 and 13\n",
      "Correlating images 9 and 14\n",
      "Correlating images 9 and 15\n",
      "Correlating images 9 and 16\n",
      "Correlating images 9 and 17\n",
      "Correlating images 9 and 18\n",
      "Correlating images 9 and 19\n",
      "Correlating images 9 and 20\n",
      "Correlating images 9 and 21\n",
      "Correlating images 9 and 22\n",
      "Correlating images 9 and 23\n",
      "Correlating images 9 and 24\n",
      "Correlating images 9 and 25\n",
      "Correlating images 9 and 26\n",
      "Correlating images 10 and 11\n",
      "Correlating images 10 and 12\n",
      "Correlating images 10 and 13\n",
      "Correlating images 10 and 14\n",
      "Correlating images 10 and 15\n",
      "Correlating images 10 and 16\n",
      "Correlating images 10 and 17\n",
      "Correlating images 10 and 18\n",
      "Correlating images 10 and 19\n",
      "Correlating images 10 and 20\n",
      "Correlating images 10 and 21\n",
      "Correlating images 10 and 22\n",
      "Correlating images 10 and 23\n",
      "Correlating images 10 and 24\n",
      "Correlating images 10 and 25\n",
      "Correlating images 10 and 26\n",
      "Correlating images 11 and 12\n",
      "Correlating images 11 and 13\n",
      "Correlating images 11 and 14\n",
      "Correlating images 11 and 15\n",
      "Correlating images 11 and 16\n",
      "Correlating images 11 and 17\n",
      "Correlating images 11 and 18\n",
      "Correlating images 11 and 19\n",
      "Correlating images 11 and 20\n",
      "Correlating images 11 and 21\n",
      "Correlating images 11 and 22\n",
      "Correlating images 11 and 23\n",
      "Correlating images 11 and 24\n",
      "Correlating images 11 and 25\n",
      "Correlating images 11 and 26\n",
      "Correlating images 12 and 13\n",
      "Correlating images 12 and 14\n",
      "Correlating images 12 and 15\n",
      "Correlating images 12 and 16\n",
      "Correlating images 12 and 17\n",
      "Correlating images 12 and 18\n",
      "Correlating images 12 and 19\n",
      "Correlating images 12 and 20\n",
      "Correlating images 12 and 21\n",
      "Correlating images 12 and 22\n",
      "Correlating images 12 and 23\n",
      "Correlating images 12 and 24\n",
      "Correlating images 12 and 25\n",
      "Correlating images 12 and 26\n",
      "Correlating images 13 and 14\n",
      "Correlating images 13 and 15\n",
      "Correlating images 13 and 16\n",
      "Correlating images 13 and 17\n",
      "Correlating images 13 and 18\n",
      "Correlating images 13 and 19\n",
      "Correlating images 13 and 20\n",
      "Correlating images 13 and 21\n",
      "Correlating images 13 and 22\n",
      "Correlating images 13 and 23\n",
      "Correlating images 13 and 24\n",
      "Correlating images 13 and 25\n",
      "Correlating images 13 and 26\n",
      "Correlating images 14 and 15\n",
      "Correlating images 14 and 16\n",
      "Correlating images 14 and 17\n",
      "Correlating images 14 and 18\n",
      "Correlating images 14 and 19\n",
      "Correlating images 14 and 20\n",
      "Correlating images 14 and 21\n",
      "Correlating images 14 and 22\n",
      "Correlating images 14 and 23\n",
      "Correlating images 14 and 24\n",
      "Correlating images 14 and 25\n",
      "Correlating images 14 and 26\n",
      "Correlating images 15 and 16\n",
      "Correlating images 15 and 17\n",
      "Correlating images 15 and 18\n",
      "Correlating images 15 and 19\n",
      "Correlating images 15 and 20\n",
      "Correlating images 15 and 21\n",
      "Correlating images 15 and 22\n",
      "Correlating images 15 and 23\n",
      "Correlating images 15 and 24\n",
      "Correlating images 15 and 25\n",
      "Correlating images 15 and 26\n",
      "Correlating images 16 and 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlating images 16 and 18\n",
      "Correlating images 16 and 19\n",
      "Correlating images 16 and 20\n",
      "Correlating images 16 and 21\n",
      "Correlating images 16 and 22\n",
      "Correlating images 16 and 23\n",
      "Correlating images 16 and 24\n",
      "Correlating images 16 and 25\n",
      "Correlating images 16 and 26\n",
      "Correlating images 17 and 18\n",
      "Correlating images 17 and 19\n",
      "Correlating images 17 and 20\n",
      "Correlating images 17 and 21\n",
      "Correlating images 17 and 22\n",
      "Correlating images 17 and 23\n",
      "Correlating images 17 and 24\n",
      "Correlating images 17 and 25\n",
      "Correlating images 17 and 26\n",
      "Correlating images 18 and 19\n",
      "Correlating images 18 and 20\n",
      "Correlating images 18 and 21\n",
      "Correlating images 18 and 22\n",
      "Correlating images 18 and 23\n",
      "Correlating images 18 and 24\n",
      "Correlating images 18 and 25\n",
      "Correlating images 18 and 26\n",
      "Correlating images 19 and 20\n",
      "Correlating images 19 and 21\n",
      "Correlating images 19 and 22\n",
      "Correlating images 19 and 23\n",
      "Correlating images 19 and 24\n",
      "Correlating images 19 and 25\n",
      "Correlating images 19 and 26\n",
      "Correlating images 20 and 21\n",
      "Correlating images 20 and 22\n",
      "Correlating images 20 and 23\n",
      "Correlating images 20 and 24\n",
      "Correlating images 20 and 25\n",
      "Correlating images 20 and 26\n",
      "Correlating images 21 and 22\n",
      "Correlating images 21 and 23\n",
      "Correlating images 21 and 24\n",
      "Correlating images 21 and 25\n",
      "Correlating images 21 and 26\n",
      "Correlating images 22 and 23\n",
      "Correlating images 22 and 24\n",
      "Correlating images 22 and 25\n",
      "Correlating images 22 and 26\n",
      "Correlating images 23 and 24\n",
      "Correlating images 23 and 25\n",
      "Correlating images 23 and 26\n",
      "Correlating images 24 and 25\n",
      "Correlating images 24 and 26\n",
      "Correlating images 25 and 26\n",
      "Performed 351.0 correlations in 0 minutes 15.208961009979248 seconds\n"
     ]
    }
   ],
   "source": [
    "findMaxima = 'gf'\n",
    "s.setGaussianFitParams(num_peaks=5,sigma_guess=3,window_radius=4)\n",
    "\n",
    "# Find all image shifts\n",
    "t0=time()\n",
    "s.findImageShifts(correlationType='cc',findMaxima=findMaxima)\n",
    "t=time()-t0\n",
    "print(\"Performed {} correlations in {} minutes {} seconds\".format(s.nz*(s.nz-1)/2,int(t/60),t%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify outliers in shift matrix\n",
    "Show the shift matrix with show)Rij() method.\n",
    "If applicable, set range of minimum and maximum images to include with set_nz(nz_min,nz_max) method.\n",
    "Find outliers with get_outliers(method, *args) method.  method parameter can be \"NN\", or \"transitivity\".  \"NN\" identifies outliers using only nearest neighbor elements of shift matrix, and requires an additional threshold parameter.  \"transitivity\" identifies outliers by identifying matrix elements which are inconsistent with physical stage positions, which must obey additive transitivity, and requires an additional threshold parameter, and an optional num_paths parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Xij and Yij matrices\n",
    "s.show_Rij()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create mask, defining unuseable data points\n",
    "\n",
    "s.set_nz(0,27)               # Set min/maz useable image indices\n",
    "s.get_outliers(\"transitivity\",10,10)       # Set outlier threshhold\n",
    "s.set_bad_images([])         # Set bad images\n",
    "\n",
    "s.show_Rij(mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optionally, add or remove points from the outlier mask that were not correctly identified\n",
    "\n",
    "correct_pairs=[[11,12],[11,13]]\n",
    "incorrect_pairs=[[1,9]]\n",
    "\n",
    "for pair in correct_pairs:\n",
    "    i,j=pair[0],pair[1]\n",
    "    s.Rij_mask[i,j]=1\n",
    "    s.Rij_mask[j,i]=1\n",
    "for pair in incorrect_pairs:\n",
    "    i,j=pair[0],pair[1]\n",
    "    s.Rij_mask[i,j]=0\n",
    "    s.Rij_mask[j,i]=0\n",
    "    \n",
    "s.show_Rij()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.Rij_mask[:5,15]=0\n",
    "s.Rij_mask[:3,18]=0\n",
    "s.Rij_mask[:8,24:26]=0\n",
    "s.Rij_mask[15,:5]=0\n",
    "s.Rij_mask[18,:3]=0\n",
    "s.Rij_mask[24:26,:8]=0\n",
    "\n",
    "s.show_Rij()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "The make_corrected_Rij() method determines the correct values for outliers in the shift matrices using transitivity, and the show_Rij_c() method shows the corrected shift matrices.\n",
    "\n",
    "This step is optional, as it is performed automatically when get_average_image() is run if not called manually.\n",
    "However, manually calling make_corrected_Rij() is recommended so that the final shift matrices can be visually inspected to ensure physical consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.make_corrected_Rij()\n",
    "s.show_Rij_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create registered image stack and average\n",
    "\n",
    "s.get_averaged_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display final image\n",
    "\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display report of registration procedure\n",
    "\n",
    "s.show_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save report of registration procedure\n",
    "\n",
    "s.save_report(\"/Users/Ben/Desktop/test_report.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that the full field of view of the original data has been preserved in the final image for computational simplicity, however, data at the edges is not physically meaningful.  All shifts are stored as 1D arrays in the attributes shifts_x and shifts_y, thus to obtain the limits of physical meaningful data, use, e.g. s.shifts_x.max(), s.shifts_x.min(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
